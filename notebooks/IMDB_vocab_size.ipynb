{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hollow-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import pickle\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "path = \"../data/\"\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [8.0, 6.0]\n",
    "plt.rcParams['figure.dpi'] = 140\n",
    "plt.rcParams[\"axes.labelsize\"] = 14\n",
    "\n",
    "#np.random.seed(250)\n",
    "nlp = spacy.load(\"en_core_sci_lg\", disable=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "external-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "path = \"../data/\"\n",
    "\n",
    "def tokenize(string):\n",
    "    doc = nlp.make_doc(string)\n",
    "    words = [doc[i].text.lower()  for i in range(len(doc)) if \n",
    "             doc[i].is_alpha and not doc[i].is_stop]\n",
    "    mn = 3\n",
    "    ngrams= [' '.join(words[i:i+n]) for n in range(1, mn+1) for i in range(len(words)-n+1)]\n",
    "    #words = [token.text.lower() for token in doc if token.is_alpha and not token.is_stop and len(token.text) > 1 ]\n",
    "    return ngrams\n",
    "\n",
    "def tokenization(train_data):\n",
    "    tokenized_texts = []\n",
    "    #print(\"Tokenization....\")\n",
    "    for _, row in train_data.iterrows():\n",
    "        #text = str(row['Abstract']) + str(row[\"Title\"])\n",
    "        text = str(row['review'])\n",
    "        words = tokenize(text)\n",
    "        tokenized_texts.append(words)\n",
    "    return tokenized_texts\n",
    "\n",
    "# TFIDF (Term frequency and inverse document frequency)\n",
    "def get_word_stat(tokenized_texts):\n",
    "    '''Words counts in documents\n",
    "    finds in how many documents this word\n",
    "    is present\n",
    "    '''\n",
    "    texts_number = len(tokenized_texts)\n",
    "    #print(\"Word Stat....\")\n",
    "    word2text_count = defaultdict(int)\n",
    "    for text in tokenized_texts:\n",
    "        uniquewords = set(text)\n",
    "        for word in uniquewords:\n",
    "            word2text_count[word] +=1\n",
    "    return word2text_count\n",
    "\n",
    "def get_doc_tfidf(words, word2text_count, N):\n",
    "    num_words = len(words)\n",
    "    word2tfidf = defaultdict(int)\n",
    "    for word in words:\n",
    "        if word2text_count[word] > 0:\n",
    "            idf = np.log(N/(word2text_count[word]))\n",
    "            word2tfidf[word] += (1/num_words) * idf\n",
    "        else:\n",
    "            word2tfidf[word] = 1\n",
    "    return word2tfidf\n",
    "\n",
    "def create_pmi_dict(tokenized_texts, targets, min_count=5):\n",
    "    #print(\"PMI dictionary ....\")\n",
    "    np.seterr(divide = 'ignore')\n",
    "    # words count\n",
    "    d = {0:defaultdict(int), 1:defaultdict(int), 'tot':defaultdict(int)}\n",
    "    for idx, words in enumerate(tokenized_texts):\n",
    "        target = targets[idx]\n",
    "        for w in words:\n",
    "            d[ target ][w] += 1\n",
    "    Dictionary = set(list(d[0].keys()) + list(d[1].keys()))\n",
    "    d['tot'] = {w:d[0][w] + d[1][w] for w in Dictionary}\n",
    "    # pmi calculation\n",
    "    N_0 = sum(d[0].values())\n",
    "    N_1 = sum(d[1].values())\n",
    "    d[0] = {w: -np.log((v/N_0 + 10**(-15)) / (0.5 * d['tot'][w]/(N_0 + N_1))) / np.log(v/N_0 + 10**(-15))\n",
    "            for w, v in d[0].items() if d['tot'][w] > min_count}\n",
    "    d[1] = {w: -np.log((v/N_1+ 10**(-15)) / (0.5 * d['tot'][w]/(N_0 + N_1))) / np.log(v/N_1 + 10**(-15))\n",
    "            for w, v in d[1].items() if d['tot'][w] > min_count}\n",
    "    del d['tot']\n",
    "    return d\n",
    "\n",
    "\n",
    "def calc_collinearity(word, words_dict, n=10):\n",
    "    new_word_emb = nlp(word).vector\n",
    "    pmi_new = 0\n",
    "    max_pmis_words = sorted(list(words_dict.items()), key=lambda x: x[1], reverse=True)[:n]\n",
    "    for w, pmi in max_pmis_words:\n",
    "        w_emb = nlp(w).vector\n",
    "        cos_similarity = \\\n",
    "        np.dot(w_emb, new_word_emb)/(np.linalg.norm(w_emb) * np.linalg.norm(new_word_emb) + 1e-12)\n",
    "        pmi_new += cos_similarity * pmi\n",
    "    return pmi_new / n\n",
    "\n",
    "\n",
    "def create_tot_pmitfidf(words, words_pmis, word2tfidf):\n",
    "    tot_pmitfidf0 = []\n",
    "    tot_pmitfidf1 = []\n",
    "    for word in words:\n",
    "        if word in words_pmis[0]:\n",
    "            tot_pmitfidf0.append( words_pmis[0][word] * word2tfidf[word] )\n",
    "        else:\n",
    "            pmi0idf = pmiidf_net.forward( nlp(word).vector )\n",
    "            #pmi0 = calc_collinearity(word, words_pmis[0])\n",
    "            tot_pmitfidf0.append( pmi0 )\n",
    "        if word in words_pmis[1]:\n",
    "            tot_pmitfidf1.append( words_pmis[1][word] * word2tfidf[word] )\n",
    "        else:\n",
    "            pmi1 = calc_collinearity(word, words_pmis[1])\n",
    "            tot_pmitfidf1.append( pmi1 )\n",
    "\n",
    "    return tot_pmitfidf0, tot_pmitfidf1\n",
    "\n",
    "\n",
    "def classify_pmi_based(words_pmis, word2text_count, tokenized_test_texts, N):\n",
    "    results = np.zeros(len(tokenized_test_texts))\n",
    "    for idx, words in enumerate(tokenized_test_texts):\n",
    "        word2tfidf = get_doc_tfidf(words, word2text_count, N)\n",
    "        # PMI - determines significance of the word for the class\n",
    "        # TFIDF - determines significance of the word for the document\n",
    "        #tot_pmi0, tot_pmi1 = create_tot_pmitfidf(words, words_pmis, word2tfidf)\n",
    "        tot_pmi0 = [ words_pmis[0][w] * word2tfidf[w] for w in set(words) if w in words_pmis[0] ]\n",
    "        tot_pmi1 = [ words_pmis[1][w] * word2tfidf[w] for w in set(words) if w in words_pmis[1] ]\n",
    "        pmi0 = np.sum(tot_pmi0)\n",
    "        pmi1 = np.sum(tot_pmi1)\n",
    "        diff = pmi1 - pmi0\n",
    "        if diff > 0.001:\n",
    "            results[idx] = 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "valuable-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(path + 'IMDB_Dataset.csv')\n",
    "indices = np.random.permutation(data_raw.index)\n",
    "data = data_raw.loc[indices]\n",
    "data = data_raw.sample(frac=1)\n",
    "data = data.replace(to_replace=['negative', 'positive'], value=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "clinical-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = int(data.shape[0] * 0.1)\n",
    "test_data = data.iloc[:idx]\n",
    "train_data = data.iloc[idx:]\n",
    "targets_train = train_data[\"sentiment\"].values\n",
    "targets_test = test_data[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adolescent-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = tokenization(train_data)\n",
    "tokenized_test_texts = tokenization(test_data)\n",
    "N = len(tokenized_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "appreciated-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2text_count = get_word_stat(tokenized_texts)\n",
    "words_pmis = create_pmi_dict(tokenized_texts, targets_train, min_count=5)\n",
    "results = classify_pmi_based(words_pmis, word2text_count, tokenized_test_texts, N)\n",
    "precision = np.sum( np.logical_and(results, targets_test) ) / np.sum(results)\n",
    "recall = np.sum( np.logical_and(results, targets_test) ) / np.sum(targets_test)\n",
    "F1 = 2 * (recall * precision)/(recall + precision)\n",
    "accuracy = (results == targets_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "considered-count",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9183098591549296\n",
      "Precision:  0.8944591029023746\n",
      "Recall:  0.9495798319327731\n",
      "F1:  0.921195652173913\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "respiratory-course",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9211267605633803\n",
      "Precision:  0.8981481481481481\n",
      "Recall:  0.9509803921568627\n",
      "F1:  0.9238095238095237\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "alert-tonight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9274647887323944\n",
      "Precision:  0.9190672153635117\n",
      "Recall:  0.938375350140056\n",
      "F1:  0.9286209286209285\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\"accuracies\":[], \"precisions\":[], \"recalls\":[], \"F1s\":[], \"size\":[]}\n",
    "dict_size = [i for i in np.arange(0.02, 1, 0.01)]\n",
    "for i in dict_size:\n",
    "    part = tokenized_texts[:int(N * i)]\n",
    "    scores[\"size\"].append(len(part))\n",
    "    word2text_count = get_word_stat(part)\n",
    "    words_pmis = create_pmi_dict(part, targets_train, min_count=5)\n",
    "\n",
    "    results = classify_pmi_based(words_pmis, word2text_count, tokenized_test_texts, N)\n",
    "\n",
    "    precision = np.sum( np.logical_and(results, targets_test) ) / np.sum(results)\n",
    "    recall = np.sum( np.logical_and(results, targets_test) ) / np.sum(targets_test)\n",
    "    F1 = 2 * (recall * precision)/(recall + precision)\n",
    "\n",
    "    accuracy = (results == targets_test).mean()\n",
    "    scores[\"accuracies\"].append( accuracy )\n",
    "    scores[\"precisions\"].append( precision )\n",
    "    scores[\"recalls\"].append( recall )\n",
    "    scores[\"F1s\"].append( F1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.plot(scores[\"size\"], scores[\"accuracies\"], label=\"Accuracy\")\n",
    "axs.plot(scores[\"size\"], scores[\"precisions\"], label=\"Precision\")\n",
    "axs.plot(scores[\"size\"], scores[\"recalls\"], label=\"Recall\")\n",
    "axs.plot(scores[\"size\"], scores[\"F1s\"], label=\"F1\")\n",
    "axs.legend(title=\"Scores\");\n",
    "axs.set(xlabel=\"Dictionary size\");\n",
    "plt.savefig(\"score_dict_size_IMDB.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scores_IMDB_ngrams.p\", \"wb\") as file:\n",
    "    pickle.dump(scores, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "given-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(tokenized_texts, targets, min_count=5):\n",
    "    np.seterr(divide = 'ignore')\n",
    "    # words count\n",
    "    d = {0:defaultdict(int), 1:defaultdict(int), 'tot':defaultdict(int)}\n",
    "    for idx, words in enumerate(tokenized_texts):\n",
    "        target = targets[idx]\n",
    "        for w in words:\n",
    "            d[ target ][w] += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "homeless-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_imdb = create_dict(tokenized_texts, targets_train, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "realistic-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dict_IMDB.p\", \"wb\") as file:\n",
    "    pickle.dump(dictionary_imdb, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
